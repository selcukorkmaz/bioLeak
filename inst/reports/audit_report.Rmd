---
title: "bioLeak audit report"
output:
  html_document:
    toc: true
    toc_depth: 2
params:
  audit: NULL
---

```{r report-setup, include=FALSE}
stopifnot(inherits(params$audit, "LeakAudit"))
aud <- params$audit
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

## Overview

```{r overview}
summary(aud)
```

## Model performance summary

```{r perf-summary}
ms <- aud@fit@metric_summary
if (!is.null(ms) && nrow(ms) > 0) {
  knitr::kable(ms)
} else {
  cat("No metric summary available.")
}
```

```{r perf-by-fold}
mf <- aud@fit@metrics
if (!is.null(mf) && nrow(mf) > 0) {
  knitr::kable(utils::head(mf, 50))
} else {
  cat("No per-fold metrics available.")
}
```

## Permutation significance test

Note: This test assesses whether predictions are better than random. It does NOT diagnose
information leakage. Use the Batch Association, Target Leakage Scan, and Duplicate Detection
sections to check for leakage.

```{r perm-significance}
pg <- aud@permutation_gap
if (!is.null(pg) && nrow(pg) > 0) {
  knitr::kable(pg)
} else {
  cat("No permutation significance results available.")
}
```

```{r perm-plot}
if (length(aud@perm_values) > 0 && any(is.finite(aud@perm_values))) {
  plot_perm_distribution(aud)
} else {
  cat("No permutation distribution available.")
}
```

## Batch association

```{r batch-assoc}
ba <- aud@batch_assoc
if (!is.null(ba) && nrow(ba) > 0) {
  knitr::kable(ba)
} else {
  cat("No batch or study association results available.")
}
```

## Confounder sensitivity

```{r confounder-sensitivity}
metric_name <- if (!is.null(aud@trail$metric)) aud@trail$metric else NULL
cs <- try(confounder_sensitivity(aud@fit, metric = metric_name), silent = TRUE)
if (inherits(cs, "try-error") || is.null(cs) || nrow(cs) == 0) {
  cat("No confounder sensitivity results available.")
} else {
  knitr::kable(utils::head(cs, 50))
}
```

```{r confounder-plot}
cs_plot <- try(plot_confounder_sensitivity(aud@fit, metric = metric_name), silent = TRUE)
if (inherits(cs_plot, "try-error")) {
  cat("Confounder sensitivity plot not available.")
}
```

## Calibration checks

```{r calibration-table}
if (identical(aud@fit@task, "binomial")) {
  cal <- try(calibration_summary(aud@fit, bins = 10), silent = TRUE)
  if (inherits(cal, "try-error")) {
    cat("Calibration summary not available.")
  } else {
    knitr::kable(cal$metrics)
  }
} else {
  cat("Calibration checks are available for binomial tasks only.")
}
```

```{r calibration-plot}
if (identical(aud@fit@task, "binomial")) {
  cal_plot <- try(plot_calibration(aud@fit, bins = 10), silent = TRUE)
  if (inherits(cal_plot, "try-error")) {
    cat("Calibration plot not available.")
  }
}
```

## Target leakage scan

```{r target-leakage}
ta <- aud@target_assoc
if (!is.null(ta) && nrow(ta) > 0) {
  threshold <- if (!is.null(aud@info$target_threshold)) aud@info$target_threshold else 0.9
  flagged <- ta[!is.na(ta$score) & ta$score >= threshold, , drop = FALSE]
  show <- if (nrow(flagged) > 0) flagged else ta
  show <- show[order(show$score, decreasing = TRUE, na.last = TRUE), , drop = FALSE]
  knitr::kable(utils::head(show, 50))
} else {
  cat("No target leakage scan results available.")
}
```

## Duplicate detection

```{r duplicates}
dd <- aud@duplicates
if (!is.null(dd) && nrow(dd) > 0) {
  knitr::kable(utils::head(dd, 50))
} else {
  cat("No duplicates detected or no duplicate check performed.")
}
```

## Provenance

```{r trail}
trail <- aud@trail
if (!is.null(trail)) {
  knitr::kable(data.frame(
    field = names(trail),
    value = vapply(trail, function(x) {
      if (length(x) == 1L) as.character(x) else "<list>"
    }, character(1)),
    stringsAsFactors = FALSE
  ))
}
```
